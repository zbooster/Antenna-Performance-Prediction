{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Antenna_Resnet34_Init.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1kZj76my_7ItCb-uJ5plkpjZulo8NwKMk",
      "authorship_tag": "ABX9TyOs48L4I7C/zHxnncGZhbA9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zbooster/Antenna-Performance-Prediction/blob/main/Antenna_Resnet34_Init.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Colab 기본 준비단계"
      ],
      "metadata": {
        "id": "5BEn5abM1OsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.데이터 준비하기"
      ],
      "metadata": {
        "id": "7tf5Yhx1dzme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "import glob\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "id = \"10Hpa4YM0KX_Ig0W9w7DbTdq62nF2UThA\"\n",
        "output = \"./open.zip\"\n",
        "\n",
        "if not os.path.isdir('./datasets'):\n",
        "  gdown.download(id=id, output=output)\n",
        "  gdown.extractall(path=output, to='./datasets')\n",
        "\n",
        "raw_data = defaultdict(pd.DataFrame)\n",
        "\n",
        "for fname in glob.glob('/content/datasets/**/*.csv', recursive=True):\n",
        "    df_name = os.path.splitext(os.path.basename(fname))[0]\n",
        "    raw_data[df_name] = pd.read_csv(fname)"
      ],
      "metadata": {
        "id": "JMemGRG3kyfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9f39a7-2f2f-45a5-a31b-083b0c0f048a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10Hpa4YM0KX_Ig0W9w7DbTdq62nF2UThA\n",
            "To: /content/open.zip\n",
            "100%|██████████| 10.0M/10.0M [00:00<00:00, 211MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.데이터 분석\n",
        "(작성중...)"
      ],
      "metadata": {
        "id": "FvPdlwk8LOi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.데이터셋(Dataset) 준비하기\n"
      ],
      "metadata": {
        "id": "zXefrXWOh9oO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1.테스트데이터 분리"
      ],
      "metadata": {
        "id": "VymiwLVVMYSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = raw_data['train'].copy()\n",
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOPFSTT8OxdP",
        "outputId": "55af17ee-b059-42db-85ab-927b899fc000"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39607"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train.filter(regex='X').copy()\n",
        "y = train.filter(regex='Y').copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)\n",
        "len(X_train), len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFhGEoD8MjOa",
        "outputId": "3ced299c-6b63-49d2-f4ec-f3baeba0055a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26536, 13071)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.데이터셋(Datasets)만들기\n",
        "* 데이터 전처리단계를 Custom datasets에 넣는다."
      ],
      "metadata": {
        "id": "wXWwW-rMMBMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AssemblyDataset(Dataset): \n",
        "    def __init__(self, X, y):\n",
        "        self.X_data = X.values\n",
        "        self.y_data = y.values\n",
        "        \n",
        "        # Resnet34에 입력하기 위해 Shape을 바꿔준다.\n",
        "        len_cx = len(self.X_data[0,:])\n",
        "        s_size = int(np.sqrt(len_cx / 3) + 1)\n",
        "        t_shape = s_size ** 2 * 3\n",
        "        p_size = t_shape - len_cx\n",
        "        self.X_data = np.pad(\n",
        "            self.X_data, (0,p_size), 'constant', constant_values=0)[:len(self.X_data)]\n",
        "        self.X_data = self.X_data.reshape(len(self.X_data), -1, s_size, s_size)\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.X_data)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        X = torch.FloatTensor(self.X_data[idx,:])\n",
        "        y = torch.FloatTensor(self.y_data[idx,:])\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "5Ix6ZbaBLpg8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = AssemblyDataset(X_train, y_train)\n",
        "vaild_dataset = AssemblyDataset(X_train, y_train)"
      ],
      "metadata": {
        "id": "pyZR19vDQ0Lg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.데이터로더(DataLoader)"
      ],
      "metadata": {
        "id": "PQ-T416QnV7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "tr_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "va_dataloader = DataLoader(train_dataset, batch_size=len(vaild_dataset), shuffle=False)"
      ],
      "metadata": {
        "id": "SMdfpW6yD3Tw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 원하는 모양으로 잘 나오는지 확인"
      ],
      "metadata": {
        "id": "7R40D7SWRYm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in tr_dataloader:\n",
        "    print(input.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-spTE02RYEY",
        "outputId": "825360ba-10da-499b-a8a5-e03cf78841d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 3, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.모델\n",
        "* device는 GPU를 사용한다."
      ],
      "metadata": {
        "id": "OgKZNghLovn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet34\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def build_network(output_size):\n",
        "    network = resnet34()\n",
        "    num_ftrs = network.fc.in_features\n",
        "    network.fc = nn.Linear(num_ftrs, output_size)\n",
        "    return network.to(device)"
      ],
      "metadata": {
        "id": "Pdy6kf0d2LDN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.옵티마이저와 스케쥴러\n",
        "* 옵티마이저는 AdamW을 사용한다."
      ],
      "metadata": {
        "id": "Om2u5R63pNsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(network, learning_rate):\n",
        "    optimizer = optim.AdamW(network.parameters(), lr=learning_rate)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "qkVW3Qcv28_t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 스케쥴러는 StepLR을 step_size와 gamma를 변경해가며 테스트할 수 있도록 작성했다.\n"
      ],
      "metadata": {
        "id": "bnaxPZsRpoep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import lr_scheduler\n",
        "\n",
        "def build_scheduler(optimizer, step_size, gamma):\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "    return exp_lr_scheduler"
      ],
      "metadata": {
        "id": "Ki3HeJRn4XIY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.학습/검증 단계(Epoch)\n",
        "* 대회에서 제공한 평가산식을 loss로 사용한다."
      ],
      "metadata": {
        "id": "YDzcapEop_gO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NRMSE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NRMSE, self).__init__()\n",
        "    self.mse = nn.MSELoss().to(device)\n",
        "\n",
        "  def forward(self, gt, preds):\n",
        "    all_nrmse = torch.zeros(14)\n",
        "    for idx in range(14):\n",
        "      rmse = torch.sqrt(self.mse(preds[:,idx], gt[:,idx]))\n",
        "      nrmse = rmse / torch.mean(torch.abs(gt[:,idx]))\n",
        "      all_nrmse[idx] = nrmse\n",
        "    score = 1.2 * torch.sum(all_nrmse[:8]) + 1.0 * torch.sum(all_nrmse[8:14])\n",
        "    return score"
      ],
      "metadata": {
        "id": "REKaGPDLhPbb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critetion = NRMSE().to(device)"
      ],
      "metadata": {
        "id": "a_GUT0QTrOCk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1.학습(Train) 단계"
      ],
      "metadata": {
        "id": "-9OFNdFCrTgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(network, loader, optimizer, scheduler):\n",
        "    network.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for idx, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "          # ➡ Forward pass\n",
        "          outputs = network(data)\n",
        "          loss = critetion(target, outputs)\n",
        "\n",
        "          # ⬅ Backward pass + weight update\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "    scheduler.step()\n",
        "    \n",
        "    epoch_loss = running_loss / len(loader)\n",
        "\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "Pzw61uAd30QZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2.검증(Validation) 단계"
      ],
      "metadata": {
        "id": "QuSNlH6MrhjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_epoch(network, loader, optimizer):\n",
        "    network.eval()\n",
        "    \n",
        "    running_loss = 0.0\n",
        "\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ➡ Forward pass\n",
        "        outputs = network(data)\n",
        "        loss = critetion(target, outputs)\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "    epoch_loss = running_loss  / len(loader)\n",
        "\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "UQbvtY4B8GEE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.수행"
      ],
      "metadata": {
        "id": "W1q43NMNrwhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 30\n",
        "network = build_network(14)\n",
        "optimizer = build_optimizer(network, 0.001)\n",
        "scheduler = build_scheduler(optimizer, 7, 0.1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    since = time.time()\n",
        "    \n",
        "    train_score = train_epoch(network, tr_dataloader, optimizer, scheduler)\n",
        "    print(\"Epoch: %4d, Train score: %.4f\" % (epoch+1, train_score), end='')\n",
        "    vaild_score = validation_epoch(network, va_dataloader, optimizer)\n",
        "    print(\", Validation score: %.4f\" % (vaild_score), end='')\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\", Time Elapsed(s): %.2f\" % (time_elapsed))"
      ],
      "metadata": {
        "id": "M19U0pCLv9jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11c9c1b-4cff-48d6-cdd2-3f135ff065da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1, Train score: 6.7053, Validation score: 2.2447, Time Elapsed(s): 6.43\n",
            "Epoch:    2, Train score: 2.1711, Validation score: 2.1362, Time Elapsed(s): 6.45\n",
            "Epoch:    3, Train score: 2.1965, Validation score: 2.3728, Time Elapsed(s): 6.48\n",
            "Epoch:    4, Train score: 2.1255, Validation score: 2.2671, Time Elapsed(s): 6.54\n",
            "Epoch:    5, Train score: 2.1034, Validation score: 2.0560, Time Elapsed(s): 6.62\n",
            "Epoch:    6, Train score: 2.0627, Validation score: 2.0456, Time Elapsed(s): 6.47\n",
            "Epoch:    7, Train score: 2.0746, Validation score: 2.0401, Time Elapsed(s): 6.46\n",
            "Epoch:    8, Train score: 2.0333, Validation score: 2.0199, Time Elapsed(s): 6.40\n",
            "Epoch:    9, Train score: 2.0210, Validation score: 2.0184, Time Elapsed(s): 6.30\n",
            "Epoch:   10, Train score: 2.0092, Validation score: 2.0130, Time Elapsed(s): 6.32\n",
            "Epoch:   11, Train score: 2.0130, Validation score: 2.0139, Time Elapsed(s): 6.31\n",
            "Epoch:   12, Train score: 2.0141, Validation score: 2.0134, Time Elapsed(s): 6.32\n",
            "Epoch:   13, Train score: 2.0074, Validation score: 2.0190, Time Elapsed(s): 6.26\n",
            "Epoch:   14, Train score: 2.0153, Validation score: 2.0136, Time Elapsed(s): 6.26\n",
            "Epoch:   15, Train score: 2.0060, Validation score: 2.0086, Time Elapsed(s): 6.35\n",
            "Epoch:   16, Train score: 1.9978, Validation score: 2.0080, Time Elapsed(s): 6.41\n",
            "Epoch:   17, Train score: 2.0002, Validation score: 2.0077, Time Elapsed(s): 6.33\n",
            "Epoch:   18, Train score: 2.0048, Validation score: 2.0078, Time Elapsed(s): 6.34\n",
            "Epoch:   19, Train score: 2.0022, Validation score: 2.0076, Time Elapsed(s): 6.42\n",
            "Epoch:   20, Train score: 2.0042, Validation score: 2.0079, Time Elapsed(s): 6.34\n",
            "Epoch:   21, Train score: 2.0004, Validation score: 2.0077, Time Elapsed(s): 6.41\n",
            "Epoch:   22, Train score: 2.0005, Validation score: 2.0076, Time Elapsed(s): 6.40\n",
            "Epoch:   23, Train score: 2.0011, Validation score: 2.0074, Time Elapsed(s): 6.32\n",
            "Epoch:   24, Train score: 2.0032, Validation score: 2.0079, Time Elapsed(s): 6.38\n",
            "Epoch:   25, Train score: 2.0013, Validation score: 2.0074, Time Elapsed(s): 6.38\n",
            "Epoch:   26, Train score: 2.0017, Validation score: 2.0076, Time Elapsed(s): 6.37\n",
            "Epoch:   27, Train score: 2.0007, Validation score: 2.0078, Time Elapsed(s): 6.30\n",
            "Epoch:   28, Train score: 2.0027, Validation score: 2.0079, Time Elapsed(s): 6.29\n",
            "Epoch:   29, Train score: 2.0004, Validation score: 2.0076, Time Elapsed(s): 6.38\n",
            "Epoch:   30, Train score: 1.9999, Validation score: 2.0075, Time Elapsed(s): 6.40\n",
            "Epoch:   31, Train score: 2.0015, Validation score: 2.0078, Time Elapsed(s): 6.32\n",
            "Epoch:   32, Train score: 2.0034, Validation score: 2.0074, Time Elapsed(s): 6.32\n",
            "Epoch:   33, Train score: 2.0025, Validation score: 2.0075, Time Elapsed(s): 6.60\n",
            "Epoch:   34, Train score: 1.9983, Validation score: 2.0074, Time Elapsed(s): 6.32\n",
            "Epoch:   35, Train score: 1.9973, Validation score: 2.0076, Time Elapsed(s): 6.40\n",
            "Epoch:   36, Train score: 2.0018, Validation score: 2.0075, Time Elapsed(s): 6.41\n",
            "Epoch:   37, Train score: 1.9989, Validation score: 2.0077, Time Elapsed(s): 6.34\n",
            "Epoch:   38, Train score: 2.0007, Validation score: 2.0075, Time Elapsed(s): 6.41\n",
            "Epoch:   39, Train score: 1.9998, Validation score: 2.0076, Time Elapsed(s): 6.40\n",
            "Epoch:   40, Train score: 2.0004, Validation score: 2.0077, Time Elapsed(s): 6.40\n",
            "Epoch:   41, Train score: 2.0016, Validation score: 2.0075, Time Elapsed(s): 6.35\n",
            "Epoch:   42, Train score: 2.0050, Validation score: 2.0074, Time Elapsed(s): 6.31\n",
            "Epoch:   43, Train score: 1.9993, Validation score: 2.0074, Time Elapsed(s): 6.39\n",
            "Epoch:   44, Train score: 1.9989, Validation score: 2.0075, Time Elapsed(s): 6.41\n",
            "Epoch:   45, Train score: 2.0001, Validation score: 2.0074, Time Elapsed(s): 6.32\n",
            "Epoch:   46, Train score: 2.0038, Validation score: 2.0077, Time Elapsed(s): 6.32\n",
            "Epoch:   47, Train score: 1.9998, Validation score: 2.0076, Time Elapsed(s): 6.39\n",
            "Epoch:   48, Train score: 1.9998, Validation score: 2.0074, Time Elapsed(s): 6.33\n",
            "Epoch:   49, Train score: 2.0022, Validation score: 2.0075, Time Elapsed(s): 6.42\n",
            "Epoch:   50, Train score: 2.0010, Validation score: 2.0075, Time Elapsed(s): 6.42\n"
          ]
        }
      ]
    }
  ]
}