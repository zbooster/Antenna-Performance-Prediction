{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install fonts-nanum* > /dev/null 2>&1\n",
    "!fc-cache -fv > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "\n",
    "file_dir = os.path.split(mpl.__file__)[0]\n",
    "font_dir = os.path.join(file_dir, 'mpl-data/fonts/ttf')\n",
    "!cp /usr/share/fonts/truetype/nanum/Nanum* {font_dir}\n",
    "!rm -rf ~/.cache/matplotlib/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Runtime Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rc('font', family='NanumGothicCoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "id = \"10Hpa4YM0KX_Ig0W9w7DbTdq62nF2UThA\"\n",
    "output = \"./open.zip\"\n",
    "\n",
    "if not os.path.isdir('./datasets'):\n",
    "  gdown.download(id=id, output=output)\n",
    "  gdown.extractall(path=output, to='./datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "raw_data = defaultdict(pd.DataFrame)\n",
    "\n",
    "for fname in glob.glob('./**/*.csv', recursive=True):\n",
    "    df_name = os.path.splitext(os.path.basename(fname))[0]\n",
    "    raw_data[df_name] = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights & Biases 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pathlib ruamel-yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzbooster\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "}\n",
    "\n",
    "metric = {\n",
    "    'name': 'LG_NRMSE'\n",
    "}\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'add_column': {\n",
    "        # 'values': ex_mean\n",
    "        'values': ex1\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Antenna_Scaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컬럼 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'X_01', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10'\n",
    "          , 'X_11', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19', 'X_20'\n",
    "          , 'X_22', 'X_26', 'X_28', 'X_29'\n",
    "          , 'X_31', 'X_32', 'X_33', 'X_38'\n",
    "          , 'X_42', 'X_44', 'X_45', 'X_46', 'X_49']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "scaler_list = [\n",
    "    ('Unscaled', None),\n",
    "    ('Standard', StandardScaler()),\n",
    "    ('log1p', FunctionTransformer(np.log1p)),\n",
    "    ('Min-Max', MinMaxScaler()),\n",
    "    ('Min-Abs', MaxAbsScaler()),\n",
    "    ('Robust', RobustScaler(quantile_range=(25, 75))),\n",
    "    ('uniform pdf', QuantileTransformer(output_distribution=\"uniform\")),\n",
    "    ('gaussian pdf', QuantileTransformer(output_distribution=\"normal\")),\n",
    "    ('L2 normalizing', Normalizer())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_data['train'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# 데이콘에서 제공한 평가함수\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14): # ignore 'ID'\n",
    "        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
    "    return score, all_nrmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "train = raw_data['train'].copy()\n",
    "\n",
    "def run_train(config=None):\n",
    "  with wandb.init(config=config):\n",
    "\n",
    "    config = wandb.config\n",
    "\n",
    "    kf = KFold(shuffle=True, random_state=13)\n",
    "    result = defaultdict(list)\n",
    "\n",
    "    # 데이터 나누기\n",
    "    X = train[columns].values\n",
    "    y = train.filter(regex='Y').values\n",
    "    for idx, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "      X_train, X_test = X[train_index], X[test_index]\n",
    "      y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "      # 파이프라인 작성\n",
    "      pipe = make_pipeline( \n",
    "        RandomForestRegressor(criterion=\"squared_error\", random_state=13, n_jobs=-1\n",
    "                            , n_estimators=400\n",
    "                            , max_depth=80\n",
    "                            , min_samples_leaf=2\n",
    "                            , min_samples_split=2)\n",
    "      )\n",
    "\n",
    "      # 학습하기\n",
    "      pipe.fit(X_train, y_train)\n",
    "\n",
    "      # 검증하기\n",
    "      y_pred = pipe.predict(X_test)\n",
    "\n",
    "      # 평가 및 기록\n",
    "      score, all_nrmse = lg_nrmse(y_test, y_pred)\n",
    "      result['LG_NRMSE'].append(score)\n",
    "      for i, v in enumerate(all_nrmse):\n",
    "        result['Y_%02d_NRMSE' % (i+1)].append(v)\n",
    "    \n",
    "    log_dict = defaultdict(float)\n",
    "    log_dict['LG_NRMSE_MEAN'] = np.mean(result['LG_NRMSE'])\n",
    "    log_dict['LG_NRMSE_BEST'] = min(result['LG_NRMSE'])\n",
    "    for i in range(14):\n",
    "      log_dict['Y_%02d_NRMSE' % (i+1)] = np.mean(result['Y_%02d_NRMSE' % (i+1)])\n",
    "    wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, run_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
